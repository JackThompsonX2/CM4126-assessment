{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "OP47SH13UK_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KAuzCCJo1VM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Research and Data Exploration"
      ],
      "metadata": {
        "id": "V6Jk08VrUTYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Imports i'll need"
      ],
      "metadata": {
        "id": "6n7JgFuS1X5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "vKjriGTr1WAp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "it seems the other tensorflow imports are gving me issues so i'm going to install it to fix it"
      ],
      "metadata": {
        "id": "aeKcVO-H2RCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxh76mf22BJV",
        "outputId": "8038937f-1ca9-4a65-e262-153a4a06d3c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, AveragePooling2D,Flatten, Dense, Conv2D,MaxPool2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "r8EnZdmb2KoC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i'm going to use kagglehub to get my dataset because it should be easier"
      ],
      "metadata": {
        "id": "_DohhVoi2l1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"hayder17/breast-cancer-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv_XLdVz2g2H",
        "outputId": "9ce64c63-9f88-4f5f-c947-3456dc57cf70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'breast-cancer-detection' dataset.\n",
            "Path to dataset files: /kaggle/input/breast-cancer-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "show me the folders to use"
      ],
      "metadata": {
        "id": "Jlpg8RAd3LpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrrFGVQT2-v5",
        "outputId": "2753f275-5b35-4fe8-bdf3-18acafca3bac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['valid', 'test', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid = path + \"/valid/\"\n",
        "test = path + '/test/'\n",
        "train = path + '/train/'"
      ],
      "metadata": {
        "id": "jVgEVRLS3RPx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(valid))\n",
        "print(os.listdir(test))\n",
        "print(os.listdir(train))"
      ],
      "metadata": {
        "id": "SDd0d3To4Yln",
        "outputId": "8215832c-1dcd-4ad1-9e03-bd48b6b6a9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1']\n",
            "['0', '1']\n",
            "['0', '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the dataset 0 = Benign and 1 = Malignant\n"
      ],
      "metadata": {
        "id": "snXlJKeT433O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = os.listdir(valid)"
      ],
      "metadata": {
        "id": "HnIOk-dp4eS3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_0 = test+\"0/\"\n",
        "\n",
        "test_1 = test+\"1/\"\n",
        "\n",
        "train_0 = train+\"0/\"\n",
        "\n",
        "train_1 = train+\"1/\"\n",
        "\n",
        "valid_0 = valid+\"0/\"\n",
        "\n",
        "valid_1 = valid+\"1/\""
      ],
      "metadata": {
        "id": "-Zex1AIB5lgJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "number of images in test"
      ],
      "metadata": {
        "id": "5x6fXntG6j07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The Number of benign images in Test {len(os.listdir(test_0))}')\n",
        "print(f'The Number of Malignant images in Test {len(os.listdir(test_1))}')\n",
        "print(f'The Number of images in Test {len(os.listdir(test_0))+len(os.listdir(test_1))}')"
      ],
      "metadata": {
        "id": "41U7yRAK6Yid",
        "outputId": "941e7b18-8556-4d3c-d0b4-6e3f82717986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Number of benign images in Test 208\n",
            "The Number of Malignant images in Test 128\n",
            "The Number of images in Test 336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "number of images in train"
      ],
      "metadata": {
        "id": "q_PDOQ648Apa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The Number of benign images in Train {len(os.listdir(train_0))}')\n",
        "print(f'The Number of Malignant images in Train {len(os.listdir(train_1))}')\n",
        "print(f'The Number of images in Train {len(os.listdir(train_0))+len(os.listdir(train_1))}')"
      ],
      "metadata": {
        "id": "dFArocZF8ARy",
        "outputId": "4599f5d6-b39c-41ea-972d-77aeb2b3baba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Number of benign images in Train 1569\n",
            "The Number of Malignant images in Train 803\n",
            "The Number of images in Train 2372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "number of images in valid set"
      ],
      "metadata": {
        "id": "Y8MoMD5E-AAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The Number of benign images in Train {len(os.listdir(valid_0))}')\n",
        "print(f'The Number of Malignant images in Train {len(os.listdir(valid_1))}')\n",
        "print(f'The Number of images in Train {len(os.listdir(valid_0))+len(os.listdir(valid_1))}')"
      ],
      "metadata": {
        "id": "-IBXfZIm9ux4",
        "outputId": "df5b52a9-1f3c-43d2-c2db-8a53cd312a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Number of benign images in Train 448\n",
            "The Number of Malignant images in Train 227\n",
            "The Number of images in Train 675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to load images and make the images all the same size and smaller and also make the data an np array"
      ],
      "metadata": {
        "id": "fYHbgGFaAIz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 128\n",
        "def get_training_data(data_dir):\n",
        "    data = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data,dtype=\"object\")"
      ],
      "metadata": {
        "id": "72wk7VLn_xqD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now i use my function on the dataset"
      ],
      "metadata": {
        "id": "zMydL2D1BKjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = get_training_data(train)\n",
        "test_ds = get_training_data(test)\n",
        "valid_ds = get_training_data(valid)"
      ],
      "metadata": {
        "id": "W5J49P4dA6td"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of training set{train_ds.shape}')\n",
        "print(f'Shape of test set{test_ds.shape}')\n",
        "print(f'Shape of validation set{valid_ds.shape}')"
      ],
      "metadata": {
        "id": "JB0tkBKeB6bF",
        "outputId": "0b5a491d-eeb2-4c16-b79e-3bb1b3cb81a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training set(2372, 2)\n",
            "Shape of test set(336, 2)\n",
            "Shape of validation set(675, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Model"
      ],
      "metadata": {
        "id": "aZLNbDYiUgF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Solution Improvement"
      ],
      "metadata": {
        "id": "afeDJskTU5uU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion and Future Direction"
      ],
      "metadata": {
        "id": "C1dwphGEVCdH"
      }
    }
  ]
}